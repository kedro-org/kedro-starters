# --- LLM setup ---
llm:
  type: langchain.ChatOpenAIDataset
  kwargs:
    model: "gpt-4o"
    temperature: 0.0
  credentials: openai

# --- Prompts ---
tool_prompt:
  type: kedro_datasets_experimental.langchain.LangChainPromptDataset
  filepath: data/response_generation/prompts/tool.txt
  template: PromptTemplate
  dataset:
    type: text.TextDataset

response_prompt:
  type: kedro_datasets_experimental.langchain.LangChainPromptDataset
  filepath: data/response_generation/prompts/response.yml
  template: ChatPromptTemplate
  dataset:
    type: yaml.YAMLDataset

intent_prompt_langfuse:
  type: kedro_datasets_experimental.langfuse.LangfusePromptDataset
  filepath: data/intent_detection/prompts/intent_prompt_langfuse.json
  prompt_name: "intent-classifier"
  prompt_type: "chat"
  credentials: langfuse_credentials
  sync_policy: local      # local|remote|strict
  mode: langchain         # langchain|sdk

# intent_prompt_opik:
#   type: kedro_datasets_experimental.opik.OpikPromptDataset
#   filepath: data/intent_detection/prompts/intent_prompt_opik.json
#   prompt_name: "intent-classifier"
#   prompt_type: "chat"
#   credentials: opik_credentials

# --- Tracing ---
intent_tracer_langfuse:
  type: kedro_datasets_experimental.langfuse.LangfuseTraceDataset
  credentials: langfuse_credentials
  mode: langchain    # langchain | openai | sdk

# intent_tracer_opik:
#  type: kedro_datasets_experimental.opik.OpikTraceDataset
#  credentials: opik_credentials
#  mode: openai    # langchain | openai | sdk
